{
  "_comment:": "Texts from web. SentencePiece tokenized. Segmented and indexed in pandas format.",
  "source_files": ["data/incoming/WIKI/wiki.txt"],
  "dataset_path": "data/datasets/TEXT_WIKI",
  "dmgr": {
    "dmgr": "text",
    "formatter": "heuristic",
    "tokenizer": "sentencepiece"
  }
}
